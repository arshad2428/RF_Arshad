{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":103417,"databundleVersionId":12473839,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-21T01:09:15.533325Z","iopub.execute_input":"2025-11-21T01:09:15.533616Z","iopub.status.idle":"2025-11-21T01:09:15.541365Z","shell.execute_reply.started":"2025-11-21T01:09:15.533597Z","shell.execute_reply":"2025-11-21T01:09:15.540351Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/mock-test-2-mse-2/sample_submission.csv\n/kaggle/input/mock-test-2-mse-2/train.csv\n/kaggle/input/mock-test-2-mse-2/test.csv\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, OrdinalEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.calibration import CalibratedClassifierCV\n\n# ==================== Load Data ====================\ndf = pd.read_csv(\"/kaggle/input/mock-test-2-mse-2/train.csv\")\ndf[\"Status_bin\"] = df[\"Status\"].map({\"D\": 0, \"C\": 1, \"CL\": 2})\n\nX = df.drop([\"Status\", \"Status_bin\", \"id\"], axis=1)\ny = df[\"Status_bin\"]\n\n# ==================== Encode categorical columns ====================\ncat_cols = X.select_dtypes(include=[\"object\"]).columns\n\n# Option 1: Use OrdinalEncoder for all categorical columns at once\n\noe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\nX[cat_cols] = oe.fit_transform(X[cat_cols].astype(str))\n\n# ==================== Fill missing values ====================\nX = X.fillna(X.median(numeric_only=True))\n\n# ==================== Cap outliers ====================\ndef cap_outliers(df, cols, lower=1, upper=99):\n    for col in cols:\n        low_val = df[col].quantile(lower / 100)\n        high_val = df[col].quantile(upper / 100)\n        df[col] = df[col].clip(low_val, high_val)\n    return df\n\nnum_cols = X.select_dtypes(include=['float64', 'int64']).columns\nX = cap_outliers(X, num_cols)\n\n# ==================== Train-test split ====================\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.02, random_state=42, stratify=y\n)\n\n# ==================== Random Forest Classifier ====================\nnum_classes = len(np.unique(y_train))\n\nrf = RandomForestClassifier(\n    n_estimators=500,\n    max_depth=None,\n    min_samples_split=5,\n    min_samples_leaf=2,\n    max_features='sqrt',\n    random_state=42,\n    n_jobs=-1\n)\n\n# Optional: Use calibrated classifier for probabilities\nmodel = CalibratedClassifierCV(base_estimator=rf, method='isotonic', cv=5)\nmodel.fit(X_train, y_train)\n\n# ==================== Evaluate on train/test ====================\ny_pred = model.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", acc)\n\ny_pred_prob = model.predict_proba(X_test)\nlog_l = log_loss(y_test, y_pred_prob, labels=model.classes_)\nprint(\"Log Loss:\", log_l)\n\n# ==================== Prepare test data ====================\ndf_test = pd.read_csv(\"/kaggle/input/mock-test-2-mse-2/test.csv\")\ntest_ids = df_test[\"id\"]\nx_test = df_test.drop([\"id\"], axis=1)\n\n# Encode categorical columns same as train\nif len(cat_cols) > 0:\n    # Use ordinal encoding fitted on train\n    x_test[cat_cols] = oe.transform(x_test[cat_cols].astype(str))\n\n# Fill missing values\nx_test = x_test.fillna(x_test.median(numeric_only=True))\n\n# ==================== Predict ====================\ny_pred1 = model.predict(x_test)\ny_pred_prob1 = model.predict_proba(x_test)\n\n# ==================== Create submission ====================\nclass_labels = model.classes_\nsubmission_cols = [f\"Status_{label}\" for label in class_labels]\n\nsubmission = pd.DataFrame(y_pred_prob1, columns=submission_cols)\nsubmission.insert(0, \"id\", test_ids)\nsubmission = submission.rename(columns={\n    \"Status_0\": \"Status_D\",\n    \"Status_1\": \"Status_C\",\n    \"Status_2\": \"Status_CL\"\n})\n\n# Reorder columns: id, Status_C, Status_CL, Status_D\nsubmission = submission[[\"id\", \"Status_C\", \"Status_CL\", \"Status_D\"]]\n\nsubmission.to_csv(\"professor_rf.csv\", index=False)\nprint(\"Submission file saved as professor_rf.csv\")\nprint(submission.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T01:10:46.507927Z","iopub.execute_input":"2025-11-21T01:10:46.508523Z","iopub.status.idle":"2025-11-21T01:11:16.982976Z","shell.execute_reply.started":"2025-11-21T01:10:46.508496Z","shell.execute_reply":"2025-11-21T01:11:16.982057Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8533333333333334\nLog Loss: 0.38290025653796705\nSubmission file saved as professor_rf.csv\n      id  Status_C  Status_CL  Status_D\n0  15000  0.963867   0.005101  0.031032\n1  15001  0.954017   0.002515  0.043468\n2  15002  0.949566   0.005294  0.045139\n3  15003  0.225272   0.077335  0.697394\n4  15004  0.945342   0.002450  0.052208\n","output_type":"stream"}],"execution_count":15}]}