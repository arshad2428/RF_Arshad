{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "md9eeVFclgH6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    log_loss,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    classification_report\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "# ==================== Load Data ====================\n",
        "df = pd.read_csv(\"/kaggle/input/mock-test-2-mse-2/train.csv\")\n",
        "df[\"Status_bin\"] = df[\"Status\"].map({\"D\": 0, \"C\": 1, \"CL\": 2})\n",
        "\n",
        "X = df.drop([\"Status\", \"Status_bin\", \"id\"], axis=1)\n",
        "y = df[\"Status_bin\"]\n",
        "\n",
        "# ==================== Encode categorical columns ====================\n",
        "cat_cols = X.select_dtypes(include=[\"object\"]).columns\n",
        "\n",
        "# Option 1: Use OrdinalEncoder for all categorical columns at once\n",
        "\n",
        "oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "X[cat_cols] = oe.fit_transform(X[cat_cols].astype(str))\n",
        "\n",
        "# ==================== Fill missing values ====================\n",
        "X = X.fillna(X.median(numeric_only=True))\n",
        "\n",
        "# ==================== Cap outliers ====================\n",
        "def cap_outliers(df, cols, lower=1, upper=99):\n",
        "    for col in cols:\n",
        "        low_val = df[col].quantile(lower / 100)\n",
        "        high_val = df[col].quantile(upper / 100)\n",
        "        df[col] = df[col].clip(low_val, high_val)\n",
        "    return df\n",
        "\n",
        "num_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
        "X = cap_outliers(X, num_cols)\n",
        "\n",
        "# ==================== Train-test split ====================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.02, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# ==================== Random Forest Classifier ====================\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=None,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    max_features='sqrt',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Optional: Use calibrated classifier for probabilities\n",
        "model = CalibratedClassifierCV(base_estimator=rf, method='isotonic', cv=5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ==================== Evaluate on train/test ====================\n",
        "y_pred = model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "y_pred_prob = model.predict_proba(X_test)\n",
        "log_l = log_loss(y_test, y_pred_prob, labels=model.classes_)\n",
        "\n",
        "\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# ======== DISPLAY ========\n",
        "print(\"Accuracy:\", acc)\n",
        "print(\"Log Loss:\", log_l)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# ==================== Prepare test data ====================\n",
        "# submission = pd.DataFrame({\n",
        "#     \"id\": test_ids,\n",
        "#     \"Status\": y_pred_labels\n",
        "# })\n",
        "\n",
        "# submission.to_csv(\"professor_rf_classes.csv\", index=False)\n",
        "# print(\"Submission saved as professor_rf_classes.csv\")\n",
        "# print(submission.head())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # ==================== Predict encoded classes ====================\n",
        "# y_pred_test = model.predict(x_test)\n",
        "\n",
        "# # ==================== Create new sequential ID ====================\n",
        "# new_ids = np.arange(1, len(x_test) + 1)\n",
        "\n",
        "# # ==================== Create final CSV ====================\n",
        "# submission = pd.DataFrame({\n",
        "#     \"id\": new_ids,\n",
        "#     \"Status\": y_pred_test\n",
        "# })\n",
        "\n",
        "# submission.to_csv(\"professor_rf_encoded_classes.csv\", index=False)\n",
        "# print(\"Saved as professor_rf_encoded_classes.csv\")\n",
        "# print(submission.head())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#  If your dataset is SMALL (<10k rows)\n",
        "# rf = RandomForestClassifier(\n",
        "#     n_estimators=300,\n",
        "#     max_depth=None,\n",
        "#     min_samples_split=3,\n",
        "#     min_samples_leaf=1,\n",
        "#     max_features='sqrt',\n",
        "#     random_state=42,\n",
        "#     n_jobs=-1\n",
        "# )\n",
        "# ⭐ If your dataset is MEDIUM (10k–100k rows)\n",
        "# rf = RandomForestClassifier(\n",
        "#     n_estimators=600,\n",
        "#     max_depth=20,\n",
        "#     min_samples_split=5,\n",
        "#     min_samples_leaf=2,\n",
        "#     max_features='sqrt',\n",
        "#     random_state=42,\n",
        "#     n_jobs=-1\n",
        "# )\n",
        "# ⭐ If your dataset is LARGE (>100k rows)\n",
        "# rf = RandomForestClassifier(\n",
        "#     n_estimators=1200,\n",
        "#     max_depth=15,\n",
        "#     min_samples_split=10,\n",
        "#     min_samples_leaf=5,\n",
        "#     max_features='log2',\n",
        "#     random_state=42,\n",
        "#     n_jobs=-1\n",
        "# )\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "2CjAF_9nlgH8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "YA-rkRbQlgH-"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}