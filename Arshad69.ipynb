{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31239,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # =========================================================\n# # FINAL UNIVERSAL MACHINE LEARNING TEMPLATE (TABULAR DATA)\n# #\n# # Handles:\n# # 1) Categorical targets  â†’ Status, Class, NObeyesdad\n# # 2) Numerical targets    â†’ price, MEDV\n# # 3) Missing values in FEATURES\n# # 4) Missing values in TARGET\n# # 5) Test WITHOUT target (normal Kaggle)\n# # 6) Test WITH target (rare exam case)\n# # 7) Single-column output (DEFAULT)\n# # 8) Multiclass PROBABILITY output (OPTIONAL â€“ COMMENTED)\n# #\n# # â— IMPORTANT:\n# # - This code WORKS AS-IS for normal questions\n# # - Multiclass probability block is COMMENTED\n# # - Uncomment ONLY if question explicitly asks\n# #\n# # â— EXTRA NOTE (FOR EXAMS):\n# # - If test.csv has NO id column\n# # - AND question explicitly says \"create id starting from 1\"\n# # - Then generating id using range(1, n+1) is CORRECT\n# # =========================================================\n\n# import pandas as pd\n# import numpy as np\n\n# from sklearn.model_selection import train_test_split, GridSearchCV\n# from sklearn.preprocessing import LabelEncoder, StandardScaler\n# from sklearn.metrics import accuracy_score, mean_squared_error, classification_report\n# from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n\n\n# # -------------------- STEP 1: Load Data --------------------\n# train = pd.read_csv(\"train.csv\")\n# test = pd.read_csv(\"test.csv\")\n\n\n# # -------------------- STEP 2: DEFINE TARGET ----------------\n# # ðŸ”´ CHANGE ONLY THIS LINE BASED ON QUESTION\n# TARGET = \"Status\"    # e.g. \"Status\", \"Class\", \"NObeyesdad\", \"price\"\n\n\n# # -------------------- STEP 3: CHECK IF TEST CONTAINS TARGET\n# # (DO NOT COMMENT)\n# test_has_target = TARGET in test.columns\n# print(\"Test contains target:\", test_has_target)\n\n\n# # -------------------- STEP 4: Separate Target & Features ---\n# y = train[TARGET]\n# train_features = train.drop(columns=[TARGET])\n\n# # Remove rows with missing target (MANDATORY)\n# mask = y.notna()\n# y = y[mask]\n# train_features = train_features.loc[mask]\n\n# # Prepare test features\n# if test_has_target:\n#     y_test_true = test[TARGET]      # ONLY for evaluation\n#     test_features = test.drop(columns=[TARGET])\n# else:\n#     test_features = test.copy()\n\n\n# # -------------------- STEP 5: SAVE ORIGINAL TEST IDs -------\n# # â— Submission id MUST match test.csv id\n# #\n# # EXAM NOTE:\n# # If test.csv DOES NOT have an id column\n# # AND question explicitly asks to \"create id starting from 1\",\n# # then range(1, len(test)+1) is CORRECT.\n# #\n# # KAGGLE NOTE:\n# # If test.csv HAS an id column, NEVER generate new ids.\n# #\n# # if \"id\" in test.columns:\n# #     test_ids = test[\"id\"]\n# # else:\n# #     test_ids = pd.Series(\n# #         range(15000, 15000 + len(test)),\n# #         name=\"id\"\n# #     )\n\n# if \"id\" in test.columns:\n#     test_ids = test[\"id\"]\n# else:\n#     test_ids = pd.Series(range(1, len(test) + 1), name=\"id\")\n\n\n# # -------------------- STEP 6: DROP ID FROM FEATURES --------\n# # id is NEVER a feature\n# for df in [train_features, test_features]:\n#     if \"id\" in df.columns:\n#         df.drop(\"id\", axis=1, inplace=True)\n\n\n# # -------------------- STEP 7: HANDLE MISSING VALUES --------\n# num_cols_train = train_features.select_dtypes(include=np.number).columns\n# num_cols_test = test_features.select_dtypes(include=np.number).columns\n\n# train_features[num_cols_train] = train_features[num_cols_train].fillna(\n#     train_features[num_cols_train].median()\n# )\n# test_features[num_cols_test] = test_features[num_cols_test].fillna(\n#     test_features[num_cols_test].median()\n# )\n\n# cat_cols_train = train_features.select_dtypes(include=\"object\").columns\n# cat_cols_test = test_features.select_dtypes(include=\"object\").columns\n\n# for col in cat_cols_train:\n#     train_features[col] = train_features[col].fillna(train_features[col].mode()[0])\n\n# for col in cat_cols_test:\n#     test_features[col] = test_features[col].fillna(test_features[col].mode()[0])\n\n\n# # -------------------- STEP 8: ENCODE FEATURES --------------\n# for col in cat_cols_train:\n#     le = LabelEncoder()\n#     train_features[col] = le.fit_transform(train_features[col])\n\n#     test_features[col] = test_features[col].map(\n#         lambda x: le.transform([x])[0] if x in le.classes_ else -1\n#     )\n\n\n# # -------------------- STEP 9: TARGET HANDLING --------------\n# target_encoder = None\n# is_categorical_target = y.dtype == \"object\"\n\n# if is_categorical_target:\n#     target_encoder = LabelEncoder()\n#     y = target_encoder.fit_transform(y)\n# # Numerical target â†’ nothing to do\n\n\n# # -------------------- STEP 10: FEATURE SCALING -------------\n# scaler = StandardScaler()\n# X_scaled = scaler.fit_transform(train_features)\n# test_scaled = scaler.transform(test_features)\n\n\n# # -------------------- STEP 11: TRAIN-TEST SPLIT ------------\n# X_train, X_val, y_train, y_val = train_test_split(\n#     X_scaled, y, test_size=0.2, random_state=42\n# )\n\n\n# # -------------------- STEP 12: MODEL SELECTION -------------\n# # RandomForestClassifier â†’ binary + multiclass\n# # RandomForestRegressor  â†’ numerical target\n# if is_categorical_target:\n#     model = RandomForestClassifier(random_state=42)\n# else:\n#     model = RandomForestRegressor(random_state=42)\n\n# model.fit(X_train, y_train)\n\n\n# # -------------------- STEP 13: EVALUATION ------------------\n# val_pred = model.predict(X_val)\n\n# if is_categorical_target:\n#     print(\"Validation Accuracy:\", accuracy_score(y_val, val_pred))\n#     print(classification_report(y_val, val_pred))\n# else:\n#     print(\"Validation RMSE:\", np.sqrt(mean_squared_error(y_val, val_pred)))\n\n\n# # -------------------- STEP 14: HYPERPARAMETER TUNING -------\n# params = {\n#     \"n_estimators\": [100, 200],\n#     \"max_depth\": [None, 10]\n# }\n\n# grid = GridSearchCV(model, params, cv=3)\n# grid.fit(X_train, y_train)\n# best_model = grid.best_estimator_\n\n\n# # -------------------- STEP 15: PREDICT TEST ----------------\n# test_pred = best_model.predict(test_scaled)\n\n# if is_categorical_target and target_encoder is not None:\n#     test_pred = target_encoder.inverse_transform(test_pred)\n\n\n# # =========================================================\n# # ðŸ”´ STEP 15B: OPTIONAL TEST EVALUATION\n# # (ONLY when test already had target AND question asks)\n# # =========================================================\n# \"\"\"\n# if test_has_target:\n#     print(\"\\n--- Test Set Evaluation ---\")\n#     if is_categorical_target:\n#         print(\"Test Accuracy:\", accuracy_score(y_test_true, test_pred))\n#     else:\n#         print(\"Test RMSE:\", np.sqrt(mean_squared_error(y_test_true, test_pred)))\n# \"\"\"\n# # =========================================================\n\n\n# # =========================================================\n# # ðŸ”´ STEP 16A: SINGLE-COLUMN SUBMISSION (DEFAULT â€“ USE THIS)\n# # =========================================================\n# submission = pd.DataFrame({\n#     \"id\": test_ids,\n#     TARGET: test_pred\n# })\n# submission.to_csv(\"submission.csv\", index=False)\n\n\n# # =========================================================\n# # ðŸ”´ STEP 16B: MULTICLASS PROBABILITY SUBMISSION (OPTIONAL)\n# # âŒ KEEP COMMENTED\n# # âŒ UNCOMMENT ONLY IF QUESTION ASKS FOR PROBABILITIES\n# # =========================================================\n# \"\"\"\n# probs = best_model.predict_proba(test_scaled)\n\n# submission = pd.DataFrame({\n#     \"id\": test_ids,\n#     \"Status_C\":  probs[:, 0],\n#     \"Status_CL\": probs[:, 1],\n#     \"Status_D\":  probs[:, 2]\n# })\n\n# submission.to_csv(\"submission.csv\", index=False)\n# \"\"\"\n# # =========================================================\n\n# print(\"submission.csv created successfully\")","metadata":{"id":"ymIIczI2DFVh"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import (\n    accuracy_score, \n    log_loss, \n    precision_score, \n    recall_score, \n    f1_score, \n    classification_report\n)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, OrdinalEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.calibration import CalibratedClassifierCV\n\n# ==================== Load Data ====================\ndf = pd.read_csv(\"/kaggle/input/mock-test-2-mse-2/train.csv\")\ndf[\"Status_bin\"] = df[\"Status\"].map({\"D\": 0, \"C\": 1, \"CL\": 2})\n\nX = df.drop([\"Status\", \"Status_bin\", \"id\"], axis=1)\ny = df[\"Status_bin\"]\n\n# ==================== Encode categorical columns ====================\ncat_cols = X.select_dtypes(include=[\"object\"]).columns\n\n# Option 1: Use OrdinalEncoder for all categorical columns at once\n\noe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\nX[cat_cols] = oe.fit_transform(X[cat_cols].astype(str))\n\n# ==================== Fill missing values ====================\nX = X.fillna(X.median(numeric_only=True))\n\n# ==================== Cap outliers ====================\ndef cap_outliers(df, cols, lower=1, upper=99):\n    for col in cols:\n        low_val = df[col].quantile(lower / 100)\n        high_val = df[col].quantile(upper / 100)\n        df[col] = df[col].clip(low_val, high_val)\n    return df\n\nnum_cols = X.select_dtypes(include=['float64', 'int64']).columns\nX = cap_outliers(X, num_cols)\n\n# ==================== Train-test split ====================\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.05, random_state=42, stratify=y\n)\n\n# ==================== Random Forest Classifier ====================\nnum_classes = len(np.unique(y_train))\n\nrf = RandomForestClassifier(\n    n_estimators=800,\n    max_depth=None,\n    min_samples_split=2,\n    min_samples_leaf=1,\n    max_features='sqrt',\n    random_state=42,\n    n_jobs=-1,\n    class_weight='balanced'\n)\n\n# Optional: Use calibrated classifier for probabilities\nmodel = CalibratedClassifierCV(base_estimator=rf, method='isotonic', cv=5)\nmodel.fit(X_train, y_train)\n\n# ==================== Evaluate on train/test ====================\ny_pred = model.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\n\n\ny_pred_prob = model.predict_proba(X_test)\nlog_l = log_loss(y_test, y_pred_prob, labels=model.classes_)\n\n\nprecision = precision_score(y_test, y_pred, average='weighted')\nrecall = recall_score(y_test, y_pred, average='weighted')\nf1 = f1_score(y_test, y_pred, average='weighted')\n\n# ======== DISPLAY ========\nprint(\"Accuracy:\", acc)\nprint(\"Log Loss:\", log_l)\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1 Score:\", f1)\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n\n\n# ==================== Prepare test data ====================\ndf_test = pd.read_csv(\"/kaggle/input/mock-test-2-mse-2/test.csv\")\ntest_ids = df_test[\"id\"]\nx_test = df_test.drop([\"id\"], axis=1)\n\n# Encode categorical columns same as train\nif len(cat_cols) > 0:\n    # Use ordinal encoding fitted on train\n    x_test[cat_cols] = oe.transform(x_test[cat_cols].astype(str))\n\n# Fill missing values\nx_test = x_test.fillna(x_test.median(numeric_only=True))\n\n# ==================== Predict ====================\ny_pred1 = model.predict(x_test)\ny_pred_prob1 = model.predict_proba(x_test)\n\n# ==================== Create submission ====================\nclass_labels = model.classes_\nsubmission_cols = [f\"Status_{label}\" for label in class_labels]\nsubmission = pd.DataFrame(y_pred_prob1, columns=submission_cols)\nsubmission.insert(0, \"id\", test_ids)\nsubmission = submission.rename(columns={\n    \"Status_0\": \"Status_D\",\n    \"Status_1\": \"Status_C\",\n    \"Status_2\": \"Status_CL\"\n})\n\n# Reorder columns: id, Status_C, Status_CL, Status_D\nsubmission = submission[[\"id\", \"Status_C\", \"Status_CL\", \"Status_D\"]]\n\nsubmission.to_csv(\"professor_rf.csv\", index=False)\nprint(\"Submission file saved as professor_rf.csv\")\nprint(submission.head())\n\n\n\n# y_pred_test = model.predict(x_test)\n\n# # Convert 0/1/2 back to D / C / CL\n# class_map = {0: \"D\", 1: \"C\", 2: \"CL\"}\n# y_pred_labels = pd.Series(y_pred_test).map(class_map)\n\n# # ==================== Create final CSV ====================\n# submission = pd.DataFrame({\n#     \"id\": test_ids,\n#     \"Status\": y_pred_labels\n# })\n\n# submission.to_csv(\"professor_rf_classes.csv\", index=False)\n# print(\"Submission saved as professor_rf_classes.csv\")\n# print(submission.head())\n\n\n# # ==================== Predict encoded classes ====================\n# y_pred_test = model.predict(x_test)\n\n# # ==================== Create new sequential ID ====================\n# new_ids = np.arange(1, len(x_test) + 1)\n\n# # ==================== Create final CSV ====================\n# submission = pd.DataFrame({\n#     \"id\": new_ids,\n#     \"Status\": y_pred_test\n# })\n\n# submission.to_csv(\"professor_rf_encoded_classes.csv\", index=False)\n# print(\"Saved as professor_rf_encoded_classes.csv\")\n# print(submission.head())\n\n\n#  If your dataset is SMALL (<10k rows)\n# rf = RandomForestClassifier(\n#     n_estimators=300,\n#     max_depth=None,\n#     min_samples_split=3,\n#     min_samples_leaf=1,\n#     max_features='sqrt',\n#     random_state=42,\n#     n_jobs=-1\n# )\n# â­ If your dataset is MEDIUM (10kâ€“100k rows)\n# rf = RandomForestClassifier(\n#     n_estimators=600,\n#     max_depth=20,\n#     min_samples_split=5,\n#     min_samples_leaf=2,\n#     max_features='sqrt',\n#     random_state=42,\n#     n_jobs=-1\n# )\n# â­ If your dataset is LARGE (>100k rows)\n# rf = RandomForestClassifier(\n#     n_estimators=1200,\n#     max_depth=15,\n#     min_samples_split=10,\n#     min_samples_leaf=5,\n#     max_features='log2',\n#     random_state=42,\n#     n_jobs=-1\n# )\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T03:20:44.110006Z","iopub.execute_input":"2025-12-19T03:20:44.110440Z","iopub.status.idle":"2025-12-19T03:20:50.400814Z","shell.execute_reply.started":"2025-12-19T03:20:44.110400Z","shell.execute_reply":"2025-12-19T03:20:50.399129Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/3237346217.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# ==================== Load Data ====================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/mock-test-2-mse-2/train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Status_bin\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Status\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"D\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CL\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/mock-test-2-mse-2/train.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/mock-test-2-mse-2/train.csv'","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}