{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5354ad83",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-30T20:04:41.756084Z",
     "iopub.status.busy": "2025-11-30T20:04:41.755737Z",
     "iopub.status.idle": "2025-11-30T20:04:43.653817Z",
     "shell.execute_reply": "2025-11-30T20:04:43.652849Z"
    },
    "papermill": {
     "duration": 1.902773,
     "end_time": "2025-11-30T20:04:43.655264",
     "exception": false,
     "start_time": "2025-11-30T20:04:41.752491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mock-test-2-mse-2/sample_submission.csv\n",
      "/kaggle/input/mock-test-2-mse-2/train.csv\n",
      "/kaggle/input/mock-test-2-mse-2/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c01afe31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T20:04:43.660739Z",
     "iopub.status.busy": "2025-11-30T20:04:43.659892Z",
     "iopub.status.idle": "2025-11-30T20:05:13.945277Z",
     "shell.execute_reply": "2025-11-30T20:05:13.944357Z"
    },
    "papermill": {
     "duration": 30.290927,
     "end_time": "2025-11-30T20:05:13.948116",
     "exception": false,
     "start_time": "2025-11-30T20:04:43.657189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/calibration.py:321: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8533333333333334\n",
      "Log Loss: 0.38290025653796705\n",
      "Precision: 0.8566498498498498\n",
      "Recall: 0.8533333333333334\n",
      "F1 Score: 0.8419406628882838\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.70      0.77        90\n",
      "           1       0.85      0.95      0.90       202\n",
      "           2       1.00      0.12      0.22         8\n",
      "\n",
      "    accuracy                           0.85       300\n",
      "   macro avg       0.90      0.59      0.63       300\n",
      "weighted avg       0.86      0.85      0.84       300\n",
      "\n",
      "Submission file saved as professor_rf.csv\n",
      "      id  Status_C  Status_CL  Status_D\n",
      "0  15000  0.963867   0.005101  0.031032\n",
      "1  15001  0.954017   0.002515  0.043468\n",
      "2  15002  0.949566   0.005294  0.045139\n",
      "3  15003  0.225272   0.077335  0.697394\n",
      "4  15004  0.945342   0.002450  0.052208\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    log_loss, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    classification_report\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# ==================== Load Data ====================\n",
    "df = pd.read_csv(\"/kaggle/input/mock-test-2-mse-2/train.csv\")\n",
    "df[\"Status_bin\"] = df[\"Status\"].map({\"D\": 0, \"C\": 1, \"CL\": 2})\n",
    "\n",
    "X = df.drop([\"Status\", \"Status_bin\", \"id\"], axis=1)\n",
    "y = df[\"Status_bin\"]\n",
    "\n",
    "# ==================== Encode categorical columns ====================\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# Option 1: Use OrdinalEncoder for all categorical columns at once\n",
    "\n",
    "oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "X[cat_cols] = oe.fit_transform(X[cat_cols].astype(str))\n",
    "\n",
    "# ==================== Fill missing values ====================\n",
    "X = X.fillna(X.median(numeric_only=True))\n",
    "\n",
    "# ==================== Cap outliers ====================\n",
    "def cap_outliers(df, cols, lower=1, upper=99):\n",
    "    for col in cols:\n",
    "        low_val = df[col].quantile(lower / 100)\n",
    "        high_val = df[col].quantile(upper / 100)\n",
    "        df[col] = df[col].clip(low_val, high_val)\n",
    "    return df\n",
    "\n",
    "num_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "X = cap_outliers(X, num_cols)\n",
    "\n",
    "# ==================== Train-test split ====================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.02, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ==================== Random Forest Classifier ====================\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=None,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Optional: Use calibrated classifier for probabilities\n",
    "model = CalibratedClassifierCV(base_estimator=rf, method='isotonic', cv=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ==================== Evaluate on train/test ====================\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "y_pred_prob = model.predict_proba(X_test)\n",
    "log_l = log_loss(y_test, y_pred_prob, labels=model.classes_)\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# ======== DISPLAY ========\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Log Loss:\", log_l)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# ==================== Prepare test data ====================\n",
    "df_test = pd.read_csv(\"/kaggle/input/mock-test-2-mse-2/test.csv\")\n",
    "test_ids = df_test[\"id\"]\n",
    "x_test = df_test.drop([\"id\"], axis=1)\n",
    "\n",
    "# Encode categorical columns same as train\n",
    "if len(cat_cols) > 0:\n",
    "    # Use ordinal encoding fitted on train\n",
    "    x_test[cat_cols] = oe.transform(x_test[cat_cols].astype(str))\n",
    "\n",
    "# Fill missing values\n",
    "x_test = x_test.fillna(x_test.median(numeric_only=True))\n",
    "\n",
    "# ==================== Predict ====================\n",
    "y_pred1 = model.predict(x_test)\n",
    "y_pred_prob1 = model.predict_proba(x_test)\n",
    "\n",
    "# ==================== Create submission ====================\n",
    "class_labels = model.classes_\n",
    "submission_cols = [f\"Status_{label}\" for label in class_labels]\n",
    "\n",
    "submission = pd.DataFrame(y_pred_prob1, columns=submission_cols)\n",
    "submission.insert(0, \"id\", test_ids)\n",
    "submission = submission.rename(columns={\n",
    "    \"Status_0\": \"Status_D\",\n",
    "    \"Status_1\": \"Status_C\",\n",
    "    \"Status_2\": \"Status_CL\"\n",
    "})\n",
    "\n",
    "# Reorder columns: id, Status_C, Status_CL, Status_D\n",
    "submission = submission[[\"id\", \"Status_C\", \"Status_CL\", \"Status_D\"]]\n",
    "\n",
    "submission.to_csv(\"professor_rf.csv\", index=False)\n",
    "print(\"Submission file saved as professor_rf.csv\")\n",
    "print(submission.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# y_pred_test = model.predict(x_test)\n",
    "\n",
    "# # Convert 0/1/2 back to D / C / CL\n",
    "# class_map = {0: \"D\", 1: \"C\", 2: \"CL\"}\n",
    "# y_pred_labels = pd.Series(y_pred_test).map(class_map)\n",
    "\n",
    "# # ==================== Create final CSV ====================\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": test_ids,\n",
    "#     \"Status\": y_pred_labels\n",
    "# })\n",
    "\n",
    "# submission.to_csv(\"professor_rf_classes.csv\", index=False)\n",
    "# print(\"Submission saved as professor_rf_classes.csv\")\n",
    "# print(submission.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # ==================== Predict encoded classes ====================\n",
    "# y_pred_test = model.predict(x_test)\n",
    "\n",
    "# # ==================== Create new sequential ID ====================\n",
    "# new_ids = np.arange(1, len(x_test) + 1)\n",
    "\n",
    "# # ==================== Create final CSV ====================\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": new_ids,\n",
    "#     \"Status\": y_pred_test\n",
    "# })\n",
    "\n",
    "# submission.to_csv(\"professor_rf_encoded_classes.csv\", index=False)\n",
    "# print(\"Saved as professor_rf_encoded_classes.csv\")\n",
    "# print(submission.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  If your dataset is SMALL (<10k rows)\n",
    "# rf = RandomForestClassifier(\n",
    "#     n_estimators=300,\n",
    "#     max_depth=None,\n",
    "#     min_samples_split=3,\n",
    "#     min_samples_leaf=1,\n",
    "#     max_features='sqrt',\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# ⭐ If your dataset is MEDIUM (10k–100k rows)\n",
    "# rf = RandomForestClassifier(\n",
    "#     n_estimators=600,\n",
    "#     max_depth=20,\n",
    "#     min_samples_split=5,\n",
    "#     min_samples_leaf=2,\n",
    "#     max_features='sqrt',\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# ⭐ If your dataset is LARGE (>100k rows)\n",
    "# rf = RandomForestClassifier(\n",
    "#     n_estimators=1200,\n",
    "#     max_depth=15,\n",
    "#     min_samples_split=10,\n",
    "#     min_samples_leaf=5,\n",
    "#     max_features='log2',\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12473839,
     "sourceId": 103417,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37.397284,
   "end_time": "2025-11-30T20:05:14.669335",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-30T20:04:37.272051",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
